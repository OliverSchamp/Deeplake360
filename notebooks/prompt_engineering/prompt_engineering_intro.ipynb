{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro to prompt engineering: Tips and Tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import load_api_keys\n",
    "load_api_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "template = \"\"\"\n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"theme\", \"year\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Input data for the prompt\n",
    "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "chain = prompt | llm \n",
    "\n",
    "response = chain.invoke(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
    "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
    "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"color\", \"emotion\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
    "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "prompt=PromptTemplate(template=formatted_prompt, input_variables=[])\n",
    "chain = prompt | llm\n",
    "\n",
    "# Run the Runnable to get the AI-generated emotion associated with the input color\n",
    "response = chain.invoke({})\n",
    "\n",
    "print(\"Color: purple\")\n",
    "print(\"Emotion:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Prompt 1\n",
    "template_question = \"\"\"What is the most powerful civilization for early aggression in the computer game 'Age of Empires 3'?\n",
    "\n",
    "Remember that Age of Empires 2 and Age of Empires 4 are very different games to Age of Empires 3.\n",
    "\n",
    "Do not suggest the Spanish civilization.\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Provide a brief description of {faction}'s best military unit and their army composition for early aggression.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"faction\"], template=template_fact)\n",
    "\n",
    "# Create the Runnable for the first prompt\n",
    "chain_question = prompt_question | llm\n",
    "\n",
    "response_question = chain_question.invoke({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "faction = response_question.content.strip()\n",
    "\n",
    "# Create the Runnable for the second prompt\n",
    "chain_fact = prompt_fact | llm\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"faction\": faction}\n",
    "\n",
    "# Run the Runnable for the second prompt\n",
    "response_fact = chain_fact.invoke(input_data)\n",
    "\n",
    "print(\"Faction:\", faction)\n",
    "print(\"Strategy:\", response_fact.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
    "    }, {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the Runnable for the few-shot prompt template\n",
    "chain = few_shot_prompt_template | llm\n",
    "\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "# Run the Runnable for the user query\n",
    "response = chain.invoke({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
