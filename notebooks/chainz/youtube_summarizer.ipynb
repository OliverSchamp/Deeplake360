{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import load_api_keys\n",
    "load_api_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def download_mp4_from_youtube(url):\n",
    "    # Set the options for the download\n",
    "    filename = 'lionhrt.mp4'\n",
    "    ydl_opts = {\n",
    "        'format': '144p[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',\n",
    "        'outtmpl': filename,\n",
    "        'quiet': True,\n",
    "    }\n",
    "\n",
    "    # Download the video file\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.extract_info(url, download=True)\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=cDbR154srUk\"\n",
    "download_mp4_from_youtube(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tainers and Z-Dutch We just like trying Russian must I mean Give me a few more Do it 3 2 release a heading or there should be aging up Not quite an 1110. Fonda, fonda, fonda, fonda. XP and gold is not really that good at the rather smegas. Wow look we're gonna do a 12A village at the very holy crap look at the age of time this. Okay that's what I mean heard. Actually now if I get that I could probably sell yeah. I think I have to sell some point to get a house. I'm gonna go for two houses. Oh maybe free. Alright boys here we go. Here we go. I'm gonna put the barracks over here so hopefully I can get my flag up still. I am nice. I can pick that up as well. Here comes the pine trine. Oh you ain't getting that boy up but ill. Okay what we need to do is wait it out. Wait a minute. Okay the only problem with this strategy as well is that I don't have my church because the church would be really nice. I'm gonna get that cuz I want to start doing. I think we've wasted enough time. Probably lost some skirmishes but you can put this back away. Why is my explorer so fucking slow to react? Hello boy. You've been on my life. A little sketch wash. You know what's coming next boys? You fucking know it. Oh yes. Don't do it. Don't burn. We're gonna get another one. We suck. I've got way too many on there. Okay let's see how he deals with a Falconet. Hopefully he's not gonna be able to age up in his time soon. He's got four. Nice. Nice. Wait a minute. Wait a minute. Stay alive. Stay alive. Wait a minute. Where's my Padre? I'm gonna find out my Fermi. I'm gonna find out my Fermi. Where's all my food? Oh shit. Oh shit. I'm gonna find out my Fermi. I'm gonna find out my Fermi. I'm gonna find out my Fermi. I'm gonna find out my Fermi.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"lionhrt.mp4\")\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('lionhrttext.txt', 'w') as file:  \n",
    "    file.write(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110922/3648987276.py:6: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"]\n",
    ")\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "with open('lionhrttext.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "texts = text_splitter.split_text(text)\n",
    "docs = [Document(page_content=t) for t in texts[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110922/3617542835.py:6: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output_summary = chain.run(docs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The speaker shares their game strategy, which includes trying different tactics, selling items for\n",
      "a house, building a church, and starting a new task. They express determination to bounce back from\n",
      "lost battles and frustration with their slow explorer. They consider using a Falconet and mention\n",
      "struggling with managing their units and resources.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a concise summary of the following:\n",
      "\n",
      "\n",
      "\"{text}\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "print( chain.llm_chain.prompt.template )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise bullet point summary of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "CONSCISE SUMMARY IN BULLET POINTS:\"\"\"\n",
    "\n",
    "BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template, \n",
    "                        input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "- Tainers and Z-Dutch are trying Russian strategies\n",
      "- They are discussing selling items to get a house and building barracks\n",
      "- They are waiting for their church to be built\n",
      "- They have lost some skirmishes but are still confident\n",
      "- They are planning to use a Falconet in their next attack\n",
      "- They are struggling with food and resources\n",
      "- They are trying to stay alive and continue their strategy.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"stuff\", \n",
    "                             prompt=BULLET_POINT_PROMPT)\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "\n",
    "wrapped_text = textwrap.fill(output_summary, \n",
    "                             width=1000,\n",
    "                             break_long_words=False,\n",
    "                             replace_whitespace=False)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The speaker discusses their strategy for playing a game, including trying out different tactics and\n",
      "selling items to get a house. They also mention wanting to build a church and starting a new task.\n",
      "Despite losing some skirmishes, the speaker remains determined and continues to strategize. They\n",
      "express frustration with their slow explorer and make a plan to deal with their opponent's Falconet.\n",
      "However, they encounter a setback when they realize they are low on resources.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def download_mp4_from_youtube(urls, job_id):\n",
    "    # This will hold the titles and authors of each downloaded video\n",
    "    video_info = []\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        # Set the options for the download\n",
    "        file_temp = f'./{job_id}_{i}.mp4'\n",
    "        ydl_opts = {\n",
    "            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',\n",
    "            'outtmpl': file_temp,\n",
    "            'quiet': True,\n",
    "        }\n",
    "\n",
    "        # Download the video file\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            result = ydl.extract_info(url, download=True)\n",
    "            title = result.get('title', \"\")\n",
    "            author = result.get('uploader', \"\")\n",
    "\n",
    "        # Add the title and author to our list\n",
    "        video_info.append((file_temp, title, author))\n",
    "\n",
    "    return video_info\n",
    "\n",
    "urls=[\"https://www.youtube.com/watch?v=mBjPyte2ZZo&t=78s\",\n",
    "    \"https://www.youtube.com/watch?v=cjs7QKJNVYM\",]\n",
    "vides_details = download_mp4_from_youtube(urls, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# load the model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# iterate through each video and transcribe\n",
    "results = []\n",
    "for video in vides_details:\n",
    "    result = model.transcribe(video[0])\n",
    "    results.append( result['text'] )\n",
    "    print(f\"Transcription for {video[0]}:\\n{result['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('text.txt', 'w') as file:  \n",
    "    for item in results:\n",
    "        file.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the texts\n",
    "with open('text.txt') as f:\n",
    "    text = f.read()\n",
    "texts = text_splitter.split_text(text)\n",
    "\n",
    "# Split the documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"]\n",
    "    )\n",
    "texts = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = [Document(page_content=t) for t in texts[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 4 embeddings in 1 batches of size 4:: 100%|██████████| 1/1 [00:09<00:00,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://oschamp/langchain_course_youtube_summarizer_2', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (4, 1)      str     None   \n",
      " metadata     json      (4, 1)      str     None   \n",
      " embedding  embedding  (4, 1536)  float32   None   \n",
      "    id        text      (4, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['5643c8c4-e318-11ef-b4aa-0242ac110002',\n",
       " '5643ca4a-e318-11ef-b4aa-0242ac110002',\n",
       " '5643cb44-e318-11ef-b4aa-0242ac110002',\n",
       " '5643cc20-e318-11ef-b4aa-0242ac110002']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"oschamp\"\n",
    "my_activeloop_dataset_name = \"langchain_course_youtube_summarizer_2\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['k'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"Use the following pieces of transcripts from a video to answer the question in bullet points and summarized. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Summarized answer in bullet points:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "- Google uses self-supervised learning in their AI program\n",
      "- They use a pre-training phase where they remove words and train a neural net to predict the missing words\n",
      "- This has been a career revolution in the last few years\n",
      "- Google uses this technique in practical applications such as content moderation on platforms like Facebook, Google, and YouTube\n",
      "- Large language models are also used in Google's AI program, but they lack a world model and have difficulty representing uncertain predictions\n",
      "- Google is constantly researching and developing new techniques, such as the joint embedding predictive architecture, to improve their AI program.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=retriever,\n",
    "                                 chain_type_kwargs=chain_type_kwargs)\n",
    "\n",
    "print( qa.run(\"Summarize the mentions of google according to their AI program\") )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
